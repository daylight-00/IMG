{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Draft Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_data(df):\n",
    "    df = df.drop(columns=[\n",
    "        ('Assay ID', 'IEDB IRI'), \n",
    "        ('Reference', 'IEDB IRI'), \n",
    "        ('Reference', 'Type'), \n",
    "        ('Reference', 'PMID'), \n",
    "        ('Reference', 'Submission ID'), \n",
    "        ('Reference', 'Authors'), \n",
    "        ('Reference', 'Journal'),\n",
    "        ('Reference', 'Title'), \n",
    "        ('Epitope', 'Epitope IRI'), \n",
    "        ('Epitope', 'Starting Position'), \n",
    "        ('Epitope', 'Ending Position'), \n",
    "        ('Epitope', 'IRI'), \n",
    "        ('Epitope', 'Synonyms'), \n",
    "        ('Epitope', 'Source Molecule IRI'), \n",
    "        ('Epitope', 'Molecule Parent IRI'), \n",
    "        ('Epitope', 'Source Organism IRI'), \n",
    "        ('Epitope', 'Species IRI'), \n",
    "        ('Epitope', 'Comments'), \n",
    "        ('Related Object', 'Epitope Relation'), \n",
    "        ('Related Object', 'Object Type'), \n",
    "        ('Related Object', 'Name'), \n",
    "        ('Related Object', 'Starting Position'), \n",
    "        ('Related Object', 'Ending Position'), \n",
    "        ('Related Object', 'IRI'), \n",
    "        ('Related Object', 'Synonyms'), \n",
    "        ('Related Object', 'Source Molecule'), \n",
    "        ('Related Object', 'Source Molecule IRI'), \n",
    "        ('Related Object', 'Molecule Parent'), \n",
    "        ('Related Object', 'Molecule Parent IRI'), \n",
    "        ('Related Object', 'Source Organism'), \n",
    "        ('Related Object', 'Source Organism IRI'), \n",
    "        ('Related Object', 'Species'), \n",
    "        ('Related Object', 'Species IRI'), \n",
    "        ('Host', 'Geolocation'), \n",
    "        ('Host', 'Geolocation IRI'), \n",
    "        ('Host', 'Sex'), \n",
    "        ('Host', 'Age'), \n",
    "        ('in vivo Antigen', 'Epitope Relation'), \n",
    "        ('in vivo Antigen', 'Object Type'), \n",
    "        ('in vivo Antigen', 'Name'), \n",
    "        ('in vivo Antigen', 'Reference Name'), \n",
    "        ('in vivo Antigen', 'Starting Position'), \n",
    "        ('in vivo Antigen', 'Ending Position'), \n",
    "        ('in vivo Antigen', 'IRI'), \n",
    "        ('in vivo Antigen', 'Source Molecule'), \n",
    "        ('in vivo Antigen', 'Source Molecule IRI'), \n",
    "        ('in vivo Antigen', 'Molecule Parent'), \n",
    "        ('in vivo Antigen', 'Molecule Parent IRI'), \n",
    "        ('in vivo Antigen', 'Source Organism'), \n",
    "        ('in vivo Antigen', 'Source Organism IRI'), \n",
    "        ('in vivo Antigen', 'Species'), \n",
    "        ('in vivo Antigen', 'Species IRI'), \n",
    "        ('in vivo Antigen', 'Adjuvants'), \n",
    "        ('in vivo Antigen', 'Route'), \n",
    "        ('in vivo Antigen', 'Dose Schedule'), \n",
    "        ('In vitro Process', 'Process Type'), \n",
    "        ('In vitro Process', 'Epitope Relation'), \n",
    "        ('In vitro Process', 'Object Type'), \n",
    "        ('In vitro Process', 'Name'), \n",
    "        ('In vitro Process', 'Reference Name'), \n",
    "        ('In vitro Process', 'Starting Position'), \n",
    "        ('In vitro Process', 'Ending Position'), \n",
    "        ('In vitro Process', 'IRI'), \n",
    "        ('In vitro Process', 'Source Molecule'), \n",
    "        ('In vitro Process', 'Source Molecule IRI'), \n",
    "        ('In vitro Process', 'Molecule Parent'), \n",
    "        ('In vitro Process', 'Molecule Parent IRI'), \n",
    "        ('In vitro Process', 'Source Organism'), \n",
    "        ('In vitro Process', 'Source Organism IRI'), \n",
    "        ('In vitro Process', 'Species'), \n",
    "        ('In vitro Process', 'Species IRI'), \n",
    "        ('MHC Restriction', 'IRI'), \n",
    "        ('MHC Restriction', 'Evidence IRI'), \n",
    "        ('Host', 'IRI'), \n",
    "        ('in vivo Process', 'Disease IRI'), \n",
    "        ('Assay', 'IRI'), \n",
    "        ('Antigen Presenting Cell', 'Source Tissue IRI'), \n",
    "        ('Antigen Presenting Cell', 'IRI'),\n",
    "        ####\n",
    "        ('Antigen Presenting Cell', 'Culture Condition'),\n",
    "        ('MHC Restriction', 'Evidence Code'),\n",
    "        ('Assay', 'Comments'),\n",
    "        ('Assay', 'Location of Assay Data in Reference'),\n",
    "        ('Assay', 'PDB ID'),\n",
    "        ('Antigen Processing', 'Comments'),\n",
    "        ('Epitope', 'Reference Name'),\n",
    "        ])\n",
    "\n",
    "    df = df[df[('Host', 'Name')] == \"Homo sapiens (human)\"]\n",
    "    df = df.drop(columns=[('Host', 'Name')])\n",
    "    df = df[(df[('MHC Restriction', 'Name')].str.contains(\"*\", regex=False, na=False, case=False)) & (df[('MHC Restriction', 'Name')].str.startswith(\"HLA\", na=False)) & (~df[('MHC Restriction', 'Name')].str.contains(\"mutant\", regex=False, na=False, case=False))]\n",
    "    \n",
    "    df = df[~df[('Epitope', 'Name')].str.contains(\"+\", regex=False, na=False, case=False)]\n",
    "    df = df[df[('Epitope', 'Object Type')] == \"Linear peptide\"]\n",
    "    df = df.drop(columns=[\n",
    "        ('Epitope', 'Object Type'), \n",
    "        ('Epitope', 'Modified residues'), \n",
    "        ('Epitope', 'Modifications')])\n",
    "    df = df[df[('MHC Restriction', 'Class')] == \"II\"]\n",
    "    df = df.drop(columns=[('MHC Restriction', 'Class')])\n",
    "    df = df[df[('Epitope', 'Name')].str.len() == 15]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = pd.read_csv(r'/home/mink/project/250228/hwj/mhc_ligand_full.csv', header=[0 , 1], low_memory=False)\n",
    "df_clean = clean_data(df.copy())\n",
    "df_clean.to_csv(r'draft.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Epi_Seq",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "HLA_Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "HLA_Name_full",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Target",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "39de2e43-19d4-4c65-af7b-44c291685b5f",
       "rows": [
        [
         "0",
         "AAAAAAAAAAAAAAA",
         "HLA-DPB1*03:01",
         "HLA-DPA1*01:03/DPB1*03:01",
         "1"
        ],
        [
         "1",
         "AAAAAAAAAAAAAAA",
         "HLA-DPB1*06:01",
         "HLA-DPA1*01:03/DPB1*06:01",
         "1"
        ],
        [
         "2",
         "AAAAAAAAAAAAAAA",
         "HLA-DQB1*03:01",
         "HLA-DQA1*05:05/DQB1*03:01",
         "1"
        ],
        [
         "3",
         "AAAAAAAAAAAAAAA",
         "HLA-DQB1*03:02",
         "HLA-DQA1*03:01/DQB1*03:02",
         "1"
        ],
        [
         "4",
         "AAAAAAAAAAAAAAA",
         "HLA-DQB1*06:02",
         "HLA-DQA1*01:02/DQB1*06:02",
         "1"
        ],
        [
         "5",
         "AAAAAAAAAAAAAQQ",
         "HLA-DQB1*03:01",
         "HLA-DQA1*05:05/DQB1*03:01",
         "1"
        ],
        [
         "6",
         "AAAAAAAAAAAGAGA",
         "HLA-DQB1*03:01",
         "HLA-DQA1*05:05/DQB1*03:01",
         "1"
        ],
        [
         "7",
         "AAAAAAAAAAGAGAG",
         "HLA-DQB1*03:01",
         "HLA-DQA1*05:05/DQB1*03:01",
         "1"
        ],
        [
         "8",
         "AAAAAAAAAGAGAGA",
         "HLA-DQB1*03:01",
         "HLA-DQA1*05:05/DQB1*03:01",
         "1"
        ],
        [
         "9",
         "AAAAAAAGAFAGRRA",
         "HLA-DQB1*03:01",
         "HLA-DQA1*05:05/DQB1*03:01",
         "1"
        ],
        [
         "10",
         "AAAAAAAPAAPAAPR",
         "HLA-DQB1*03:01",
         "HLA-DQA1*05:05/DQB1*03:01",
         "1"
        ],
        [
         "11",
         "AAAAAAKAAAKAAQF",
         "HLA-DPB1*14:01",
         "HLA-DPA1*02:01/DPB1*14:01",
         "1"
        ],
        [
         "12",
         "AAAAAAKVPAKKITA",
         "HLA-DPB1*14:01",
         "HLA-DPA1*02:01/DPB1*14:01",
         "1"
        ],
        [
         "13",
         "AAAAAATASIAGAPT",
         "HLA-DRB1*15:01",
         "HLA-DRB1*15:01",
         "0"
        ],
        [
         "14",
         "AAAAAGGAAAAAARQ",
         "HLA-DPB1*03:01",
         "HLA-DPA1*01:03/DPB1*03:01",
         "1"
        ],
        [
         "15",
         "AAAAAGGAAAAAARQ",
         "HLA-DPB1*06:01",
         "HLA-DPA1*01:03/DPB1*06:01",
         "1"
        ],
        [
         "16",
         "AAAAAGGAAAAAARQ",
         "HLA-DPB1*14:01",
         "HLA-DPA1*02:01/DPB1*14:01",
         "1"
        ],
        [
         "17",
         "AAAAAGGAAAAAARQ",
         "HLA-DQB1*02:02",
         "HLA-DQA1*02:01/DQB1*02:02",
         "1"
        ],
        [
         "18",
         "AAAAAVATGKKRKRP",
         "HLA-DPB1*14:01",
         "HLA-DPA1*02:01/DPB1*14:01",
         "1"
        ],
        [
         "19",
         "AAAAAYEAAFAATVP",
         "HLA-DRB1*01:01",
         "HLA-DRB1*01:01",
         "1"
        ],
        [
         "20",
         "AAAAAYEAAFAATVP",
         "HLA-DRB1*04:01",
         "HLA-DRB1*04:01",
         "1"
        ],
        [
         "21",
         "AAAAAYEAAFAATVP",
         "HLA-DRB1*04:05",
         "HLA-DRB1*04:05",
         "1"
        ],
        [
         "22",
         "AAAAAYEAAFAATVP",
         "HLA-DRB1*07:01",
         "HLA-DRB1*07:01",
         "1"
        ],
        [
         "23",
         "AAAAAYEAAFAATVP",
         "HLA-DRB1*15:01",
         "HLA-DRB1*15:01",
         "1"
        ],
        [
         "24",
         "AAAAAYEAAFAATVP",
         "HLA-DRB4*01:01",
         "HLA-DRB4*01:01",
         "1"
        ],
        [
         "25",
         "AAAAAYEAAFAATVP",
         "HLA-DRB5*01:01",
         "HLA-DRB5*01:01",
         "1"
        ],
        [
         "26",
         "AAAAFAGLSREEALR",
         "HLA-DRB1*11:01",
         "HLA-DRB1*11:01",
         "1"
        ],
        [
         "27",
         "AAAAGWQTLSAALDA",
         "HLA-DPB1*01:01",
         "HLA-DPA1*02:01/DPB1*01:01",
         "1"
        ],
        [
         "28",
         "AAAAGWQTLSAALDA",
         "HLA-DPB1*02:01",
         "HLA-DPA1*01:03/DPB1*02:01",
         "1"
        ],
        [
         "29",
         "AAAAGWQTLSAALDA",
         "HLA-DPB1*04:01",
         "HLA-DPA1*01:03/DPB1*04:01",
         "1"
        ],
        [
         "30",
         "AAAAGWQTLSAALDA",
         "HLA-DPB1*04:02",
         "HLA-DPA1*03:01/DPB1*04:02",
         "1"
        ],
        [
         "31",
         "AAAAGWQTLSAALDA",
         "HLA-DPB1*05:01",
         "HLA-DPA1*02:01/DPB1*05:01",
         "0"
        ],
        [
         "32",
         "AAAAGWQTLSAALDA",
         "HLA-DQB1*02:01",
         "HLA-DQA1*05:01/DQB1*02:01",
         "1"
        ],
        [
         "33",
         "AAAAGWQTLSAALDA",
         "HLA-DQB1*03:01",
         "HLA-DQA1*05:01/DQB1*03:01",
         "1"
        ],
        [
         "34",
         "AAAAGWQTLSAALDA",
         "HLA-DQB1*03:02",
         "HLA-DQA1*03:01/DQB1*03:02",
         "1"
        ],
        [
         "35",
         "AAAAGWQTLSAALDA",
         "HLA-DQB1*05:01",
         "HLA-DQA1*01:01/DQB1*05:01",
         "1"
        ],
        [
         "36",
         "AAAAGWQTLSAALDA",
         "HLA-DQB1*06:02",
         "HLA-DQA1*01:02/DQB1*06:02",
         "1"
        ],
        [
         "37",
         "AAAAGWQTLSAALDA",
         "HLA-DRB1*01:01",
         "HLA-DRB1*01:01",
         "1"
        ],
        [
         "38",
         "AAAAGWQTLSAALDA",
         "HLA-DRB1*03:01",
         "HLA-DRB1*03:01",
         "0"
        ],
        [
         "39",
         "AAAAGWQTLSAALDA",
         "HLA-DRB1*04:01",
         "HLA-DRB1*04:01",
         "1"
        ],
        [
         "40",
         "AAAAGWQTLSAALDA",
         "HLA-DRB1*04:04",
         "HLA-DRB1*04:04",
         "1"
        ],
        [
         "41",
         "AAAAGWQTLSAALDA",
         "HLA-DRB1*04:05",
         "HLA-DRB1*04:05",
         "1"
        ],
        [
         "42",
         "AAAAGWQTLSAALDA",
         "HLA-DRB1*07:01",
         "HLA-DRB1*07:01",
         "1"
        ],
        [
         "43",
         "AAAAGWQTLSAALDA",
         "HLA-DRB1*08:02",
         "HLA-DRB1*08:02",
         "1"
        ],
        [
         "44",
         "AAAAGWQTLSAALDA",
         "HLA-DRB1*09:01",
         "HLA-DRB1*09:01",
         "1"
        ],
        [
         "45",
         "AAAAGWQTLSAALDA",
         "HLA-DRB1*11:01",
         "HLA-DRB1*11:01",
         "1"
        ],
        [
         "46",
         "AAAAGWQTLSAALDA",
         "HLA-DRB1*12:01",
         "HLA-DRB1*12:01",
         "1"
        ],
        [
         "47",
         "AAAAGWQTLSAALDA",
         "HLA-DRB1*13:02",
         "HLA-DRB1*13:02",
         "0"
        ],
        [
         "48",
         "AAAAGWQTLSAALDA",
         "HLA-DRB1*15:01",
         "HLA-DRB1*15:01",
         "1"
        ],
        [
         "49",
         "AAAAGWQTLSAALDA",
         "HLA-DRB3*01:01",
         "HLA-DRB3*01:01",
         "0"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 163984
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epi_Seq</th>\n",
       "      <th>HLA_Name</th>\n",
       "      <th>HLA_Name_full</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>HLA-DPB1*03:01</td>\n",
       "      <td>HLA-DPA1*01:03/DPB1*03:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>HLA-DPB1*06:01</td>\n",
       "      <td>HLA-DPA1*01:03/DPB1*06:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>HLA-DQB1*03:01</td>\n",
       "      <td>HLA-DQA1*05:05/DQB1*03:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>HLA-DQB1*03:02</td>\n",
       "      <td>HLA-DQA1*03:01/DQB1*03:02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAAAAAAAAAAAAA</td>\n",
       "      <td>HLA-DQB1*06:02</td>\n",
       "      <td>HLA-DQA1*01:02/DQB1*06:02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163979</th>\n",
       "      <td>YYVGYLQPRTFLLKY</td>\n",
       "      <td>HLA-DRB1*15:01</td>\n",
       "      <td>HLA-DRB1*15:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163980</th>\n",
       "      <td>YYVWKSYVHVVDGCN</td>\n",
       "      <td>HLA-DRB1*04:04</td>\n",
       "      <td>HLA-DRB1*04:04</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163981</th>\n",
       "      <td>YYVWKSYVHVVDGCN</td>\n",
       "      <td>HLA-DRB1*07:01</td>\n",
       "      <td>HLA-DRB1*07:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163982</th>\n",
       "      <td>YYVWKSYVHVVDGCN</td>\n",
       "      <td>HLA-DRB1*15:01</td>\n",
       "      <td>HLA-DRB1*15:01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163983</th>\n",
       "      <td>YYYIQQDTKGDYQKA</td>\n",
       "      <td>HLA-DRB1*03:01</td>\n",
       "      <td>HLA-DRB1*03:01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163984 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Epi_Seq        HLA_Name              HLA_Name_full  Target\n",
       "0       AAAAAAAAAAAAAAA  HLA-DPB1*03:01  HLA-DPA1*01:03/DPB1*03:01       1\n",
       "1       AAAAAAAAAAAAAAA  HLA-DPB1*06:01  HLA-DPA1*01:03/DPB1*06:01       1\n",
       "2       AAAAAAAAAAAAAAA  HLA-DQB1*03:01  HLA-DQA1*05:05/DQB1*03:01       1\n",
       "3       AAAAAAAAAAAAAAA  HLA-DQB1*03:02  HLA-DQA1*03:01/DQB1*03:02       1\n",
       "4       AAAAAAAAAAAAAAA  HLA-DQB1*06:02  HLA-DQA1*01:02/DQB1*06:02       1\n",
       "...                 ...             ...                        ...     ...\n",
       "163979  YYVGYLQPRTFLLKY  HLA-DRB1*15:01             HLA-DRB1*15:01       0\n",
       "163980  YYVWKSYVHVVDGCN  HLA-DRB1*04:04             HLA-DRB1*04:04       0\n",
       "163981  YYVWKSYVHVVDGCN  HLA-DRB1*07:01             HLA-DRB1*07:01       0\n",
       "163982  YYVWKSYVHVVDGCN  HLA-DRB1*15:01             HLA-DRB1*15:01       0\n",
       "163983  YYYIQQDTKGDYQKA  HLA-DRB1*03:01             HLA-DRB1*03:01       1\n",
       "\n",
       "[163984 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_data(df):\n",
    "    df_clean = pd.DataFrame()\n",
    "    df_clean['Epi_Seq'] = df[('Epitope', 'Name')]\n",
    "    df_clean['HLA_Name_full'] = df[('MHC Restriction', 'Name')]\n",
    "    df_clean['HLA_Name'] = df_clean['HLA_Name_full'].apply(lambda x: 'HLA-'+x.split('/')[-1] if '/' in x else x)\n",
    "    df_clean['Target'] = df[('Assay', 'Qualitative Measurement')].apply(lambda x: 0 if str(x) == 'Negative' else 1).values\n",
    "    df_clean = df_clean.groupby(['Epi_Seq', 'HLA_Name', 'HLA_Name_full'])['Target'].max().reset_index()\n",
    "    return df_clean\n",
    "\n",
    "df = pd.read_csv(r'/home/mink/project/250303/filtered1.csv', header=[0 , 1], low_memory=False)\n",
    "df_full = clean_data(df.copy())\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131187, 4) (32797, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = df_full\n",
    "data['stratify_col'] = data['HLA_Name_full'].astype(str) + '_' + data['Target'].astype(str)\n",
    "\n",
    "class_counts = data['stratify_col'].value_counts()\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "stratify_data = data[data['stratify_col'].isin(valid_classes)]\n",
    "non_stratify_data = data[~data['stratify_col'].isin(valid_classes)]\n",
    "\n",
    "train_strat, test_strat = train_test_split(\n",
    "    stratify_data, \n",
    "    test_size=0.2, \n",
    "    stratify=stratify_data['stratify_col'], \n",
    "    random_state=100\n",
    ")\n",
    "\n",
    "train_non_strat, test_non_strat = train_test_split(\n",
    "    non_stratify_data, \n",
    "    test_size=0.2, \n",
    "    random_state=100\n",
    ")\n",
    "\n",
    "train = pd.concat([train_strat, train_non_strat])\n",
    "test = pd.concat([test_strat, test_non_strat])\n",
    "train = train.drop(columns=['stratify_col'])\n",
    "test = test.drop(columns=['stratify_col'])\n",
    "train_sorted = train.sort_values(by=['Epi_Seq', 'HLA_Name', 'Target', 'HLA_Name_full'], ascending=[True, True, False, True])\n",
    "test_sorted = test.sort_values(by=['Epi_Seq', 'HLA_Name', 'Target', 'HLA_Name_full'], ascending=[True, True, False, True])\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "\n",
    "train.to_csv(r'train_non_div.csv', index=False)\n",
    "test.to_csv(r'test_non_div.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(r'/home/alpha/project/IMG/data/250303/train_non_div.csv')\n",
    "test = pd.read_csv(r'/home/alpha/project/IMG/data/250303/test_non_div.csv')\n",
    "\n",
    "train_sorted = train.sort_values(by=['Epi_Seq', 'HLA_Name', 'Target', 'HLA_Name_full'], ascending=[True, True, False, True])\n",
    "train_dedup = train_sorted.drop_duplicates(subset=['Epi_Seq', 'HLA_Name'], keep='first')\n",
    "test_sorted = test.sort_values(by=['Epi_Seq', 'HLA_Name', 'Target', 'HLA_Name_full'], ascending=[True, True, False, True])\n",
    "train_sorted = train.sort_values(['Target'], ascending=False)\n",
    "test_dedup = test_sorted.drop_duplicates(subset=['Epi_Seq', 'HLA_Name'], keep='first')\n",
    "print(len(train_dedup), len(test_dedup))\n",
    "\n",
    "# train_dedup = train_dedup.drop(columns=['HLA_Name_full'])\n",
    "# test_dedup = test_dedup.drop(columns=['HLA_Name_full'])\n",
    "\n",
    "train_dedup.to_csv(r'train.csv', index=False)\n",
    "test_dedup.to_csv(r'test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20029370248697645\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_dedup = pd.read_csv(r'/home/hwjang/project/IMG/data/250303/train.csv')\n",
    "test_dedup = pd.read_csv(r'/home/hwjang/project/IMG/data/250303/test.csv')\n",
    "\n",
    "train_dedup['type'] = 'train'\n",
    "test_dedup['type'] = 'test'\n",
    "\n",
    "train_plus_test = pd.concat([train_dedup, test_dedup])\n",
    "# find duplicates\n",
    "duplicates = train_plus_test[train_plus_test.duplicated(subset=['Epi_Seq', 'HLA_Name'], keep=False)]\n",
    "duplicates = duplicates.sort_values(by=['Epi_Seq', 'HLA_Name', 'HLA_Name_full', 'Target'], ascending=[True, True, True, False])\n",
    "drop_duplicates = duplicates.drop_duplicates(subset=['Epi_Seq', 'HLA_Name'], keep='first')\n",
    "\n",
    "train_plus_test = train_plus_test.sort_values(by=['Epi_Seq', 'HLA_Name', 'HLA_Name_full', 'Target'], ascending=[True, True, True, False])\n",
    "train_plus_test_wo_duplicates = train_plus_test.drop_duplicates(subset=['Epi_Seq', 'HLA_Name'], keep='first')\n",
    "train_pure = train_plus_test_wo_duplicates[train_plus_test_wo_duplicates['type'] == 'train']\n",
    "test_pure = train_plus_test_wo_duplicates[train_plus_test_wo_duplicates['type'] == 'test']\n",
    "\n",
    "print(len(test_pure)/(len(train_pure)+len(test_pure)))\n",
    "train_pure = train_pure.drop(columns=['type'])\n",
    "test_pure = test_pure.drop(columns=['type'])\n",
    "train_pure.to_csv(r'train.csv', index=False)\n",
    "test_pure.to_csv(r'test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. IC50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/home/mink/project/250303/filtered1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m     df_clean[\u001b[33m'\u001b[39m\u001b[33mTarget\u001b[39m\u001b[33m'\u001b[39m] = (df_clean[\u001b[33m'\u001b[39m\u001b[33mlog_IC50\u001b[39m\u001b[33m'\u001b[39m] < np.log10(\u001b[32m500\u001b[39m)).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df_clean\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/home/mink/project/250303/filtered1.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m df_ic50 = clean_data(df.copy())\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# df_ic50\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# df_clean.to_csv(r'ic50.csv', index=False)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/venv/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: '/home/mink/project/250303/filtered1.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_data(df):\n",
    "    df = df[(df[('Assay', 'Response measured')].str.contains(\"IC50\", regex=False, na=False, case=False)) & ((df[('Assay', 'Measurement Inequality')].isna()) | (df[('Assay', 'Measurement Inequality')] == \"=\"))]\n",
    "    df = df[~df[('Assay', 'Quantitative measurement')].isna()]\n",
    "    df_clean = pd.DataFrame()\n",
    "    df_clean['Epi_Seq'] = df[('Epitope', 'Name')]\n",
    "    df_clean['HLA_Name_full'] = df[('MHC Restriction', 'Name')]\n",
    "    df_clean['HLA_Name'] = df_clean['HLA_Name_full'].apply(lambda x: 'HLA-'+x.split('/')[-1] if '/' in x else x)\n",
    "    df_clean['IC50'] = pd.to_numeric(df[('Assay', 'Quantitative measurement')], errors='coerce')\n",
    "    df_clean['log_IC50'] = np.log10(df_clean['IC50'])\n",
    "    df_clean = df_clean.groupby(['Epi_Seq', 'HLA_Name'])['log_IC50'].mean().reset_index()\n",
    "    df_clean['Target'] = (df_clean['log_IC50'] < np.log10(500)).astype(int)\n",
    "    return df_clean\n",
    "\n",
    "df = pd.read_csv(r'/home/mink/project/250303/filtered1.csv', header=[0 , 1], low_memory=False)\n",
    "df_ic50 = clean_data(df.copy())\n",
    "# df_ic50\n",
    "# df_clean.to_csv(r'ic50.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34019, 4) (8506, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = df_ic50\n",
    "data['Target_bin'] = pd.qcut(data['Target'], q=100, duplicates='drop')\n",
    "data['stratify_col'] = data['HLA_Name'].astype(str) + '_' + data['Target_bin'].astype(str)\n",
    "\n",
    "class_counts = data['stratify_col'].value_counts()\n",
    "valid_classes = class_counts[class_counts >= 2].index\n",
    "stratify_data = data[data['stratify_col'].isin(valid_classes)]\n",
    "non_stratify_data = data[~data['stratify_col'].isin(valid_classes)]\n",
    "\n",
    "train_strat, test_strat = train_test_split(\n",
    "    stratify_data, \n",
    "    test_size=0.2, \n",
    "    stratify=stratify_data['stratify_col'], \n",
    "    random_state=100\n",
    ")\n",
    "\n",
    "train_non_strat, test_non_strat = train_test_split(\n",
    "    non_stratify_data, \n",
    "    test_size=0.2, \n",
    "    random_state=100\n",
    ")\n",
    "\n",
    "train = pd.concat([train_strat, train_non_strat])\n",
    "test = pd.concat([test_strat, test_non_strat])\n",
    "train = train.drop(columns=['Target_bin', 'stratify_col'])\n",
    "test = test.drop(columns=['Target_bin', 'stratify_col'])\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "train.to_csv(r'train_ic50.csv', index=False)\n",
    "test.to_csv(r'test_ic50.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
